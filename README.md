ðŸ“Œ Project Overview

This project extracts, transforms, and analyzes historical stock data for multiple companies. It includes:

ETL pipeline: Fetch data from Yahoo Finance, clean it, and load into PostgreSQL.

Analysis scripts: Perform multiple financial analyses and generate charts and tables.

Outputs: All results are saved in the outputs/ folder, organized by analysis type.

ðŸ—‚ Folder Structure
stock-etl/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Raw downloaded stock CSVs
â”‚   â””â”€â”€ cleaned/          # Cleaned CSVs ready for DB
â”‚
â”œâ”€â”€ outputs/              # Analysis results (images & CSVs)
â”‚   â”œâ”€â”€ analyze_data/
â”‚   â”œâ”€â”€ correlation_volatility/
â”‚   â”œâ”€â”€ cumulative_returns/
â”‚   â”œâ”€â”€ drawdowns/
â”‚   â”œâ”€â”€ moving_average_crossovers/
â”‚   â”œâ”€â”€ return_vs_volatility/
â”‚   â”œâ”€â”€ sector_daily_returns/
â”‚   â”œâ”€â”€ sector_trends/
â”‚   â”œâ”€â”€ top_movers_sector_summary/
â”‚   â”œâ”€â”€ trading_volume_analysis/
â”‚   â””â”€â”€ volatility_vs_return/
â”‚
â”œâ”€â”€ venv/                 # Python virtual environment
â”‚
â”œâ”€â”€ analyze_data.py
â”œâ”€â”€ check_cleaned.py
â”œâ”€â”€ clean_data.py
â”œâ”€â”€ correlation_volatility.py
â”œâ”€â”€ cumulative_returns.py
â”œâ”€â”€ db_connection.py
â”œâ”€â”€ drawdowns.py
â”œâ”€â”€ export_summary_tables.py
â”œâ”€â”€ fetch_data.py
â”œâ”€â”€ load_to_db.py
â”œâ”€â”€ moving_average_crossovers.py
â”œâ”€â”€ return_vs_volatility.py
â”œâ”€â”€ seasonality_analysis.py
â”œâ”€â”€ sector_daily_returns.py
â”œâ”€â”€ sector_trends.py
â”œâ”€â”€ test_db_connection.py
â”œâ”€â”€ top_movers_sector_summary.py
â”œâ”€â”€ trading_volume_analysis.py
â””â”€â”€ volatility_vs_return.py

ðŸ›  Setup Instructions

Clone the repository

git clone https://github.com/<username>/stock-etl-analysis.git
cd stock-etl-analysis


Create a Python virtual environment

python -m venv venv
venv\Scripts\activate   # Windows
# or
source venv/bin/activate # Mac/Linux


Install required packages

pip install -r requirements.txt


(Create requirements.txt with all needed libraries: pandas, yfinance, matplotlib, seaborn, sqlalchemy, psycopg2)

Set up PostgreSQL

Create database: stock_etl

Update credentials in db_connection.py if needed

Test connection:

python test_db_connection.py


Fetch & clean data

python fetch_data.py
python clean_data.py


Load cleaned data into DB

python load_to_db.py


Run analysis scripts
Each script generates its own output folder inside outputs/:

python analyze_data.py
python correlation_volatility.py
python cumulative_returns.py
python drawdowns.py
python moving_average_crossovers.py
python return_vs_volatility.py
python seasonality_analysis.py
python sector_daily_returns.py
python sector_trends.py
python top_movers_sector_summary.py
python trading_volume_analysis.py
python volatility_vs_return.py

ðŸ“Š Analyses Included

Average daily returns per stock

Closing price trends

Daily returns histogram

Sector-wise trends & returns

Moving average crossovers

Return vs volatility

Correlation matrix & rolling volatility

Top & bottom movers by daily return

Trading volume analysis

Max drawdowns (risk measure)

Cumulative returns

Seasonality analysis (monthly/quarterly patterns)

Export summary tables (returns, volatility, etc.)

âœ… Notes

Outputs are saved as PNG charts and CSV tables in the outputs/ folder.

Each analysis script has its own folder in outputs/ for organization.

Data cleaning handles missing values, duplicates, and numeric conversions.

Analyses are modular â€” you can run scripts independently.
